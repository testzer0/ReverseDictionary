{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18nn1wO8s-bL",
        "outputId": "91e89d0f-c316-42bb-9749-f4ecc393661b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 17.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 69.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=f30c305835e2a3cffb8191a42ac3ed45526bc15dcb994aa5c568fd3b8843258f\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 48.7 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 68.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 63.2 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 74.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.6.2-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n",
            "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.2.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2022.3.0)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.11.0+cu113)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.8.1-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.8.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.8)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.25.11)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.12)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
            "Installing collected packages: pyDeprecate, torchmetrics, pytorch-lightning\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.6.2 torchmetrics-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7UNBIsqtJqT"
      },
      "outputs": [],
      "source": [
        "# Imports go here -- a bit shabby for now...\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import urllib.request\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "import zipfile\n",
        "import pickle\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, BertForMaskedLM, BertModel, get_linear_schedule_with_warmup\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoX4-gjHHTOF"
      },
      "outputs": [],
      "source": [
        "def free_memory():\n",
        "  with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg728izOxLfm",
        "outputId": "d8b110b4-09c2-47cf-f86b-c8b4b4ca395c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount my Drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPv91brIx9E3"
      },
      "outputs": [],
      "source": [
        "# Some flags for the rest of the notebook\n",
        "force_download = False\n",
        "process_dictionaries=True\n",
        "filter_using_glove = True\n",
        "dont_use_edmt = True\n",
        "dont_use_webster = True\n",
        "dont_use_unix = False\n",
        "use_lstm_model = True\n",
        "use_multi_layers = False\n",
        "force_restart_training = False\n",
        "NUM_TARGET_EPOCHS = 50          # Used for linear schedule\n",
        "if use_multi_layers:\n",
        "  if dont_use_unix:\n",
        "    CHECKPT_DIR = \"/content/gdrive/MyDrive/rd-checkpt-bl-2\"\n",
        "  else:\n",
        "    CHECKPT_DIR = \"/content/gdrive/MyDrive/rd-checkpt-bl-4\"\n",
        "else:\n",
        "  if dont_use_unix:\n",
        "    CHECKPT_DIR = \"/content/gdrive/MyDrive/rd-checkpt-bl-1\"\n",
        "  else:\n",
        "    CHECKPT_DIR = \"/content/gdrive/MyDrive/rd-checkpt-bl-3\"\n",
        "sample_bad_words = ['timewrn', 'svahng', 'bulletinyyy', 'seabream', 'srivalo', 'nortelnet', 'piyanart', 'prohertrib', 'canyonres']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNh-N5SmwbBP",
        "outputId": "1ba00d63-9719-4f17-88bd-45799f01615c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "if force_download or not os.path.isfile('/content/gdrive/MyDrive/webster_dict.json'):\n",
        "  urllib.request.urlretrieve (\"https://raw.githubusercontent.com/matthewreagan/WebstersEnglishDictionary/master/dictionary.json\", \"/content/gdrive/MyDrive/webster_dict.json\")\n",
        "if force_download or not os.path.isfile('/content/gdrive/MyDrive/edmt_dict.json'):\n",
        "  urllib.request.urlretrieve (\"https://raw.githubusercontent.com/eddydn/DictionaryDatabase/master/EDMTDictionary.json\", \"/content/gdrive/MyDrive/edmt_dict.json\")\n",
        "nltk.download('wordnet')\n",
        "wordnet = [(synset.lemma_names()[0], synset.definition()) for synset in wn.all_synsets()]\n",
        "wordnet = [(word, defn) for (word, defn) in wordnet if '_' not in word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcsTW3vJhFfy"
      },
      "outputs": [],
      "source": [
        "if force_download or not os.path.isfile('/content/gdrive/MyDrive/glove_6B_100d.pkl'):\n",
        "  urllib.request.urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \"glove.6B.zip\")\n",
        "  with zipfile.ZipFile(\"glove.6B.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "  print('Indexing word vectors.')\n",
        "  embeddings_index = {}\n",
        "  f = open('glove.6B.100d.txt', encoding='utf-8')\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "  f.close()\n",
        "\n",
        "  print('Found %s word vectors.' % len(embeddings_index))\n",
        "  pickle.dump({'embeddings_index' : embeddings_index } , open('/content/gdrive/MyDrive/glove_6B_100d.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNqz10wDkmBm",
        "outputId": "4e4669e3-a455-4437-fbe8-bb257f8d9ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example glove vector for 'sprint':  [ 1.2558    -0.32234    0.04832    0.36313   -0.012474  -0.67533\n",
            " -0.15519   -0.10026   -1.0433    -0.0051245  0.84508    0.69359\n",
            " -0.41752   -0.59553   -0.7022    -0.44532   -0.07182   -0.014373\n",
            "  0.085832  -0.38478    0.17784    0.42696    0.70415    1.0822\n",
            "  0.13701    0.048887   0.13159    0.36777    0.43866   -0.8762\n",
            " -0.60843    0.74679   -0.081127  -0.95482    1.4353    -0.1464\n",
            " -0.40491    1.2206    -0.016826   1.285      1.024     -0.0481\n",
            " -0.32355   -0.65945   -0.84005    0.60295    0.8954    -0.50376\n",
            "  0.58893   -0.38534   -0.30326   -0.19669    0.91021    0.43647\n",
            "  0.50445   -1.371     -0.88019    1.4        1.5329     0.32102\n",
            "  0.09122   -0.05632    1.0116     0.20832    0.56912   -0.14315\n",
            " -0.17157    0.42336    0.55502    0.11152   -0.30011   -0.55684\n",
            " -0.87482    0.070793   0.20729    0.24309    0.36296   -0.58297\n",
            " -0.038588  -1.1104     0.42161   -0.88943    0.12108    0.95354\n",
            " -0.3903    -0.25821   -0.18965    0.018633   0.64512    0.29789\n",
            " -0.19105    0.44094   -0.32775    0.036318   0.24655   -0.43001\n",
            " -0.25712    0.59839    0.51813    0.64381  ]\n"
          ]
        }
      ],
      "source": [
        "glove_vectors = pickle.load(open('/content/gdrive/MyDrive/glove_6B_100d.pkl', 'rb'))['embeddings_index']\n",
        "print(\"Example glove vector for 'sprint': \", glove_vectors['sprint'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrAmDz8QzV7w"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  \"\"\"\n",
        "  Cleans the text. For now, a no-op\n",
        "  \"\"\"\n",
        "  return text\n",
        "\n",
        "def remove_duplicates(dictionary):\n",
        "  \"\"\"\n",
        "  The EDMT dictionary has duplicates, e.g. two definitions of 'A'.\n",
        "  Given a list of (word, meaning pairs), throws away all but the first definition for each word.\n",
        "  https://stackoverflow.com/questions/29563953/most-pythonic-way-to-remove-tuples-from-a-list-if-first-element-is-a-duplicate\n",
        "  \"\"\"\n",
        "  return list(OrderedDict(dictionary[::-1]).items())[::-1]\n",
        "\n",
        "def split_definitions_webster(combined, min_word_count=3):\n",
        "  \"\"\"\n",
        "  Split a string giving multiple definitions into its constitutents, and then filter by the minimum word count. Webster uses the convention -\n",
        "  1. First definition 2. Second definition 3. ...\n",
        "  \"\"\"\n",
        "  max_count = 0\n",
        "  last_index = -1\n",
        "  splits = [0]\n",
        "  while True:\n",
        "    search_for = \"{}.\".format(max_count+1)\n",
        "    found_index = combined.find(search_for)\n",
        "    if found_index <= last_index:\n",
        "      break\n",
        "    splits.append(found_index)\n",
        "    last_index = found_index\n",
        "    max_count += 1\n",
        "  if max_count <= 1:\n",
        "    defs = [combined.strip()]\n",
        "  else:\n",
        "    defs = [combined[i+2:j].strip() for i,j in zip(splits, splits[1:]+[None])]\n",
        "  return [defn for defn in defs if len(defn.split()) >= min_word_count]\n",
        "\n",
        "def split_definitions_edmt(combined, min_word_count=5):\n",
        "  \"\"\"\n",
        "  Split a string giving multiple definitions into its constitutents, and then filter by the minimum word count. EDMT uses the convention -\n",
        "  First definition ; Second definition ; ...\n",
        "  \"\"\"\n",
        "  if ';' in combined:\n",
        "    defs = [defn.strip() for defn in combined.split(';')]\n",
        "  else:\n",
        "    defs = [combined.strip()]\n",
        "  return [defn for defn in defs if len(defn.split()) >= min_word_count]\n",
        "\n",
        "def should_use_definition(word, definition, min_prefix_overlap=6, retain_probability = 0):\n",
        "  \"\"\"\n",
        "  Some definitions are just poor for training. Consider:\n",
        "  'The quality of being brutal' - brutalistic\n",
        "  There are a lot of examples like this among our training data -- we thus weed out those definitions where the word\n",
        "  shares a prefix of length >= min_prefix_overlap with a word in the definition.\n",
        "  We overlook a few cases with probability retain_probability\n",
        "  \"\"\"\n",
        "  min_prefix_overlap = min(min_prefix_overlap, len(word))\n",
        "  ok = True\n",
        "  for def_word in definition.split():\n",
        "    if len(def_word) < min_prefix_overlap:\n",
        "      continue\n",
        "    if def_word[:min_prefix_overlap].lower() == word[:min_prefix_overlap].lower():\n",
        "      ok = False\n",
        "      break\n",
        "  if ok:\n",
        "    return True\n",
        "  elif retain_probability > 0 and random.random() < retain_probability:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def process_dictionary(dictionary, name):\n",
        "  \"\"\"\n",
        "  Split definitions and filter them.\n",
        "  \"\"\"\n",
        "  processed = []\n",
        "  for word, defn in dictionary:\n",
        "    if name == 'webster':\n",
        "      defs = split_definitions_webster(defn)\n",
        "    elif name == 'edmt':\n",
        "      defs = split_definitions_edmt(defn)\n",
        "    else:\n",
        "      defs = [defn]\n",
        "    for split_defn in defs:\n",
        "      if should_use_definition(word, split_defn):\n",
        "        processed.append((word, split_defn))\n",
        "  return processed\n",
        "\n",
        "def glove_filter(dictionary):\n",
        "  \"\"\"\n",
        "  Throw out those entries where the word is not in glove\n",
        "  \"\"\"\n",
        "  dictionary = [(word, defn) for (word, defn) in dictionary if word in glove_vectors]\n",
        "  return dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4ARaE1jxnuP"
      },
      "outputs": [],
      "source": [
        "def read_webster_dict(path=\"/content/gdrive/MyDrive/webster_dict.json\"):\n",
        "  with open(path) as f:\n",
        "    webster = json.load(f)\n",
        "  return remove_duplicates([(key.lower(), clean_text(value)) for key,value in webster.items()])\n",
        "\n",
        "def read_edmt_dict(path=\"/content/gdrive/MyDrive/edmt_dict.json\"):\n",
        "  with open(path) as f:\n",
        "    edmt = json.load(f)\n",
        "  return remove_duplicates([(entry['word'].lower(), clean_text(entry['description'])) for entry in edmt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyptubaYzxyr",
        "outputId": "d41d0911-e269-47ab-aa17-9c9ac74fc255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Webster has 102217 word-definition pairs.\n",
            "('chap', \"1. To cause to open in slits or chinks; to split; to cause the skin of to crack or become rough. Then would unbalanced heat licentious reign, Crack the dry hill, and chap the russet plain. Blackmore. Nor winter's blast chap her fair face. Lyly. 2. To strike; to beat. [Scot.]\\n\\n1. To crack or open in slits; as, the earth chaps; the hands chap. 2. To strike; to knock; to rap. [Scot.]\\n\\n1. A cleft, crack, or chink, as in the surface of the earth, or in the skin. 2. A division; a breach, as in a party. [Obs.] Many clefts and chaps in our council board. T. Fuller. 3. A blow; a rap. [Scot.]\\n\\n1. One of the jaws or the fleshy covering of a jaw; -- commonly in the plural, and used of animals, and colloquially of human beings. His chaps were all besmeared with crimson blood. Cowley. He unseamed him [Macdonald] from the nave to the chaps. Shak. 2. One of the jaws or cheeks of a vise, etc.\\n\\n1. A buyer; a chapman. [Obs.] If you want to sell, here is your chap. Steele. 2. A man or boy; a youth; a fellow. [Colloq.]\\n\\nTo bargain; to buy. [Obs.]\")\n",
            "EDMT has 110474 word-definition pairs.\n",
            "('evicted', 'of Evict')\n",
            "WordNet has 88440 word-definition pairs.\n",
            "('big', 'feeling self-importance')\n",
            "Unix has 89930 word-definition pairs.\n",
            "('starlight', 'the light of the stars')\n",
            "Webster has 64574 word-definition pairs after processing.\n",
            "('dauber', '(Copperplate Print.)  A pad or ball of rags, covered over with canvas, for inking plates; a dabber.')\n",
            "EDMT has 56336 word-definition pairs after processing.\n",
            "('uncinata', 'A division of marine chaetopod annelids which are furnished with uncini, as the serpulas and sabellas.')\n",
            "Webster has 25307 word-definition pairs after Glove filtering.\n",
            "('nearness', 'The state or quality of being near; -- used in the various senses of the adjective.')\n",
            "EDMT has 28291 word-definition pairs after Glove filtering.\n",
            "('shoot', 'An inclined plane, either artificial or natural, down which timber, coal, etc., are caused to slide')\n",
            "WordNet has 61027 word-definition pairs after Glove filtering.\n",
            "('sod', 'an informal British term for a youth or man')\n",
            "Unix has 89930 word-definition pairs after Glove filtering.\n",
            "('defrost', 'make or become free of frost or ice')\n"
          ]
        }
      ],
      "source": [
        "webster = read_webster_dict()\n",
        "edmt = read_edmt_dict()\n",
        "unix = pickle.load(open('/content/gdrive/MyDrive/unix-dictionary.pkl', 'rb'))['dictionary']\n",
        "print(\"Webster has {} word-definition pairs.\".format(len(webster)))\n",
        "print(random.choice(webster))\n",
        "print(\"EDMT has {} word-definition pairs.\".format(len(edmt)))\n",
        "print(random.choice(edmt))\n",
        "print(\"WordNet has {} word-definition pairs.\".format(len(wordnet)))\n",
        "print(random.choice(wordnet))\n",
        "print(\"Unix has {} word-definition pairs.\".format(len(unix)))\n",
        "print(random.choice(unix))\n",
        "if process_dictionaries:\n",
        "  webster = process_dictionary(webster, 'webster')\n",
        "  edmt = process_dictionary(edmt, 'edmt')\n",
        "  print(\"Webster has {} word-definition pairs after processing.\".format(len(webster)))\n",
        "  print(random.choice(webster))\n",
        "  print(\"EDMT has {} word-definition pairs after processing.\".format(len(edmt)))\n",
        "  print(random.choice(edmt))\n",
        "if filter_using_glove:\n",
        "  webster = glove_filter(webster)\n",
        "  edmt = glove_filter(edmt)\n",
        "  wordnet = glove_filter(wordnet)\n",
        "  unix = glove_filter(unix)\n",
        "  print(\"Webster has {} word-definition pairs after Glove filtering.\".format(len(webster)))\n",
        "  print(random.choice(webster))\n",
        "  print(\"EDMT has {} word-definition pairs after Glove filtering.\".format(len(edmt)))\n",
        "  print(random.choice(edmt))\n",
        "  print(\"WordNet has {} word-definition pairs after Glove filtering.\".format(len(wordnet)))\n",
        "  print(random.choice(wordnet))\n",
        "  print(\"Unix has {} word-definition pairs after Glove filtering.\".format(len(unix)))\n",
        "  print(random.choice(unix))\n",
        "if dont_use_edmt:\n",
        "  edmt = []\n",
        "if dont_use_webster:\n",
        "  webster = []\n",
        "if dont_use_unix:\n",
        "  unix = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-8o3DaVz12A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "5d582974fe76462f92e2d957aa31d57d",
            "1fdbf3001762477c9261e1b7648c10ef",
            "4b60c84d3e88466d8593a169b7e751f2",
            "34bf1db35ad447ea98ad39b00bce5d14",
            "48b20c56669e4e378eed28883b8a8807",
            "bc9fba806780492795ee3c72f1eab3f4",
            "05a9c56edf1f41e2a627365a26b51569",
            "d52c2ff788db41828f3d92abbd153cca",
            "347b136abd1f48dd931b8654f92ee8e5",
            "1996ca31014e430eac7a5ba4eaed6ff3",
            "085e3edfb2c94706b01d5bf07a40602b",
            "a06643ada44c417ab144dfd1e3147b0a",
            "55b10b8b85ae493b88c41226189aedc0",
            "7f243f1931314cdf82f1abf1f23a9b40",
            "cf4835f94f41464a858916f1b80bb7c2",
            "3960e22357fb4a918aeb9454e9d74318",
            "380142a4448e44bc94c4b8bcdcb1055f",
            "c467eab7e57149ad95dc8d3376903293",
            "f18492e87ee74868b8b482bf91fd8043",
            "87c6878092f64393ada9b65599827146",
            "23a2a6234a384683a9f54a3d356cc9b5",
            "ccf3c03711af4cfd9dd516ab081644b3",
            "9f9702994f2a46b9aecd4d7804d48a88",
            "349e26524c5b49afad8fcf350657c755",
            "16998aeb988c47208383f64b16ae4d5b",
            "3e4b2a2f879b47a38d615323c1f6e00b",
            "adaade3fce094873bc2b45c19c0e9574",
            "a7191804896d4295bc28a27d5d183538",
            "351345989f79465ca4ab48fc4d94282a",
            "341e26b547eb4294bf34323f91815ccb",
            "5b1b3fffea8e436aa61542fd987fe5e2",
            "6cafec97633547f698b3999c4bd17796",
            "57fdc89b532a44b48354364a87766bde",
            "bf37d8334526400a88ed2f64fbd1b5b0",
            "f38d8e899ae84fec9b79c86885a95d69",
            "33f42f6992ec45c6942009a7b82801bd",
            "1e07c1e24d9c4a9eb1ceb69eef368acf",
            "2ce529c0f097411dab55b1f581dd5cbe",
            "71bba25cb87f43a5934597d43d0610ec",
            "5c114c121020453a80b3f674549ac071",
            "8a104ebe00ff427bbe8f84e6f46a453e",
            "a01aa2977b0e4cc0bf5ef1e5fbb13a0e",
            "466e7d9b5b6747139e100d084ca15501",
            "32bf7a57fed64da49ce5c8bb01552c05"
          ]
        },
        "outputId": "c0f587c4-8934-4516-bd44-c6d343f4c9df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d582974fe76462f92e2d957aa31d57d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a06643ada44c417ab144dfd1e3147b0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f9702994f2a46b9aecd4d7804d48a88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf37d8334526400a88ed2f64fbd1b5b0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7p5WR1J6SNT"
      },
      "outputs": [],
      "source": [
        "def encode_data(data, tokenizer, using_lstm_model=False, max_def_length=128):\n",
        "  \"\"\"\n",
        "  Removes newlines, then encodes the definition of each word in the input. Prunes away those inputs whose encoded length exceeds\n",
        "  max_length. Also returns the encoded gold-truth outputs.\n",
        "  Observation - the encoded word is anywhere from 2 to 9 tokens long. Since a word may correspond to more than one token,\n",
        "  it is hard to enforce a 1-token rule. Hence, we just enforce that the output is at most 10 tokens long.\n",
        "  \"\"\"\n",
        "  num_total = len(data)\n",
        "  encoded_def = []\n",
        "  encoded_def_attn_masks = []\n",
        "  encoded_targets = []\n",
        "  for i in range(num_total):\n",
        "    word = data[i][0]\n",
        "    definition = data[i][1].replace('\\n','')\n",
        "    iids = tokenizer.encode(definition, add_special_tokens=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")[0]\n",
        "    if iids.shape[-1] != 128:\n",
        "      continue\n",
        "    attn_mask = (iids != tokenizer.pad_token_id).int()\n",
        "    if word == '':\n",
        "      target = torch.zeros(100)\n",
        "    else:\n",
        "      target = torch.tensor(glove_vectors[word])\n",
        "    encoded_def.append(iids)\n",
        "    encoded_def_attn_masks.append(attn_mask)\n",
        "    encoded_targets.append(target)\n",
        "  encoded_def = torch.stack(encoded_def)\n",
        "  encoded_def_attn_masks = torch.stack(encoded_def_attn_masks)\n",
        "  encoded_targets = torch.stack(encoded_targets)\n",
        "  return (encoded_def, encoded_def_attn_masks, encoded_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrqGrq1p7XII"
      },
      "outputs": [],
      "source": [
        "combined_dataset = webster + edmt + wordnet + unix\n",
        "encoded_dataset = encode_data(combined_dataset, bert_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_T69eev6jdJ",
        "outputId": "d724e661-7dd1-40ac-86cd-03fffbcc4d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall, using 150957 examples.\n",
            "Example encoded sentence:\n",
            "tensor([ 101, 3143,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "Example encoded target:\n",
            "tensor([ 2.0031e-03, -3.6897e-01,  1.1625e-01, -2.8270e-01,  1.1229e+00,\n",
            "         3.5139e-01,  1.9718e-01,  1.1062e-01, -5.6098e-01,  7.1374e-01,\n",
            "         8.7406e-01,  3.4401e-01,  5.3574e-01,  2.1201e-01, -8.1760e-02,\n",
            "         7.2439e-01,  4.4829e-01,  3.7731e-01,  1.2571e+00, -2.4806e-01,\n",
            "         7.0922e-01, -6.1941e-01, -2.0994e-01,  4.9950e-01,  6.5734e-01,\n",
            "        -1.8841e-01,  2.9085e-01,  9.4882e-02,  5.9975e-01,  6.9906e-01,\n",
            "        -5.4740e-01, -2.7479e-01, -1.5648e-01,  2.2423e-01,  5.1054e-02,\n",
            "         3.2784e-01, -8.0002e-02, -1.3950e-01,  2.5812e-01, -5.3947e-01,\n",
            "         5.5520e-01,  1.1601e+00, -1.0909e-01,  1.0129e+00,  2.7354e-01,\n",
            "        -2.6593e-01, -3.1130e-02, -7.3966e-01,  1.0275e-01,  7.7313e-02,\n",
            "        -2.5032e-01,  1.4773e-01,  6.4496e-02, -1.1805e-01,  4.2927e-02,\n",
            "        -1.4429e+00, -1.2226e-01, -2.0707e-01, -1.2275e-01,  5.9147e-03,\n",
            "        -2.1125e-01,  1.2929e+00, -4.2878e-01, -1.5807e-01,  1.0158e+00,\n",
            "        -3.5501e-01,  2.0010e-02,  8.4601e-02,  2.9829e-02, -1.0109e+00,\n",
            "         6.2327e-01,  9.5190e-01,  3.8567e-01,  3.0806e-01, -2.8295e-01,\n",
            "         9.7122e-01, -2.5890e-01, -6.1076e-01,  1.2401e-01, -1.1142e+00,\n",
            "        -3.9854e-01,  4.1142e-01,  2.4682e-01,  8.5517e-01, -1.0165e+00,\n",
            "        -1.9317e-01,  5.5757e-01, -6.7521e-01,  2.6805e-01,  7.5978e-01,\n",
            "        -1.4579e-02, -4.3740e-01, -3.8641e-01, -2.7397e-01,  2.1404e-02,\n",
            "        -2.4202e-01, -3.3429e-01, -1.5463e-04,  4.5120e-01, -5.8476e-01])\n"
          ]
        }
      ],
      "source": [
        "print(\"Overall, using {} examples.\".format(encoded_dataset[0].shape[0]))\n",
        "print(\"Example encoded sentence:\\n{}\".format(encoded_dataset[0][14]))\n",
        "print(\"Example encoded target:\\n{}\".format(encoded_dataset[2][14]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtVBc6geBh2-"
      },
      "outputs": [],
      "source": [
        "def train_val_test_split(encoded_dataset):\n",
        "  \"\"\"\n",
        "  Splits the dataset into train, validation and test datasets. Currently, 92%, 4.8% and 3.2% of the samples go to the training, validation\n",
        "  and test sets, respectively.\n",
        "  \"\"\"\n",
        "  train_enc_def, val_test_enc_def, train_targets, val_test_targets = train_test_split(encoded_dataset[0], encoded_dataset[2], random_state=199, test_size=0.08)\n",
        "  train_attn_masks, val_test_attn_masks, _, _ = train_test_split(encoded_dataset[1], encoded_dataset[2], random_state=199, test_size=0.08)\n",
        "  val_enc_def, test_enc_def, val_targets, test_targets = train_test_split(val_test_enc_def, val_test_targets, random_state=1700, test_size=0.4)\n",
        "  val_attn_masks, test_attn_masks, _, _ = train_test_split(val_test_attn_masks, val_test_targets, random_state=1700, test_size=0.4)\n",
        "\n",
        "  return {\n",
        "      'train' : (train_enc_def, train_attn_masks, train_targets),\n",
        "      'validation' : (val_enc_def, val_attn_masks, val_targets),\n",
        "      'test' : (test_enc_def, test_attn_masks, test_targets)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rbw1c1_8Ml3",
        "outputId": "4100e94e-cf9d-4e7c-99fc-9cf17ba564a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train examples : 138880\n",
            "Number of validation examples : 7246\n",
            "Number of test examples : 4831\n"
          ]
        }
      ],
      "source": [
        "split_dataset = train_val_test_split(encoded_dataset)\n",
        "print(\"Number of train examples : {}\".format(split_dataset['train'][0].shape[0]))\n",
        "print(\"Number of validation examples : {}\".format(split_dataset['validation'][0].shape[0]))\n",
        "print(\"Number of test examples : {}\".format(split_dataset['test'][0].shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0QRY09Jps64"
      },
      "outputs": [],
      "source": [
        "class BertLSTM(nn.Module):\n",
        "  \"\"\"\n",
        "  BERT -> LSTM -> Linear\n",
        "  \"\"\"\n",
        "  def __init__(self, out_dim=100, seq_len=128):\n",
        "    super().__init__()\n",
        "    self.out_dim = out_dim\n",
        "    self.seq_len = seq_len\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    self.hidden_size = self.bert.config.hidden_size\n",
        "    self.LSTM = nn.LSTM(self.hidden_size, self.hidden_size, bidirectional=True)\n",
        "    self.Linear = nn.Linear(self.hidden_size*2, self.out_dim)\n",
        "    self.train_mode = True\n",
        "\n",
        "  def train(self):\n",
        "    self.train_mode = True\n",
        "\n",
        "  def eval(self):\n",
        "    self.train_mode = False\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    outputs = self.bert(input_ids,attention_mask)\n",
        "    encoded_layers, pooled_output = outputs.last_hidden_state, outputs.pooler_output\n",
        "    seq_lens = encoded_layers.shape[0] * [self.seq_len]\n",
        "    encoded_layers = encoded_layers.permute(1, 0, 2)\n",
        "    enc_hiddens, (last_hidden, last_cell) = self.LSTM(nn.utils.rnn.pack_padded_sequence(encoded_layers, seq_lens))\n",
        "    output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)\n",
        "    output_hidden = nn.functional.dropout(output_hidden,0.2)\n",
        "    if self.train_mode:\n",
        "      output_hidden = nn.functional.dropout(output_hidden,0.2)\n",
        "    return self.Linear(output_hidden)\n",
        "\n",
        "class BertMultiLSTM(nn.Module):\n",
        "  \"\"\"\n",
        "  BERT -> 4 x (LSTM + Dropout) -> Linear\n",
        "  \"\"\"\n",
        "  def __init__(self, out_dim=100, seq_len=128):\n",
        "    super().__init__()\n",
        "    self.out_dim = out_dim\n",
        "    self.seq_len = seq_len\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    self.hidden_size = self.bert.config.hidden_size\n",
        "    self.LSTM = nn.LSTM(input_size=self.hidden_size, hidden_size=self.hidden_size, num_layers=4, dropout=0.1, bidirectional=True)\n",
        "    self.Linear = nn.Linear(self.hidden_size*2, self.out_dim)\n",
        "    self.train_mode = True\n",
        "\n",
        "  def train(self):\n",
        "    self.train_mode = True\n",
        "\n",
        "  def eval(self):\n",
        "    self.train_mode = False\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    outputs = self.bert(input_ids,attention_mask)\n",
        "    encoded_layers, pooled_output = outputs.last_hidden_state, outputs.pooler_output\n",
        "    seq_lens = encoded_layers.shape[0] * [self.seq_len]\n",
        "    encoded_layers = encoded_layers.permute(1, 0, 2)\n",
        "    enc_hiddens, (last_hidden, last_cell) = self.LSTM(nn.utils.rnn.pack_padded_sequence(encoded_layers, seq_lens))\n",
        "    output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)\n",
        "    if self.train_mode:\n",
        "      output_hidden = nn.functional.dropout(output_hidden,0.2)\n",
        "    return self.Linear(output_hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9f8ce995b6ca4f94b10e57b19d0cf2af",
            "d47690128a134680a60b5813d0c0ff83",
            "eb2ba6dd6baa43c69e34935885bbce6a",
            "c1c1155b1a6f4220b3d857ed71b507a4",
            "6787fe18dd0f464ca7962b6430a26be3",
            "40d4ac620cc64d10af68252512ac375c",
            "2a140f7c06734d008b6cf007ad9adad6",
            "06f5aea3055148f18fa6bcbce9f5a5b0",
            "7f7d5d829bd14ec1900d46b2bd6d4b1a",
            "e5710e209df1435488c286ab3a3e0cc8",
            "17337d42ecfe45889a3be40b95aa6b83"
          ]
        },
        "id": "UdTUXKFT8c4c",
        "outputId": "32920e01-3f02-4b23-a949-74d54c6b5024"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f8ce995b6ca4f94b10e57b19d0cf2af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertLSTM(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (LSTM): LSTM(768, 768, bidirectional=True)\n",
            "  (Linear): Linear(in_features=1536, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "if use_multi_layers:\n",
        "  bert_lstm_model = BertMultiLSTM()\n",
        "else:\n",
        "  bert_lstm_model = BertLSTM()\n",
        "print(bert_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ7RFvv69uA7"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = TensorDataset(*split_dataset['train'])\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "validation_dataset = TensorDataset(*split_dataset['validation'])\n",
        "validation_sampler = RandomSampler(validation_dataset)\n",
        "validation_dataloader = DataLoader(validation_dataset, sampler=validation_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ifb3GVajaIM",
        "outputId": "53581ae4-0704-4db8-93bd-79d69fb2080c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Using GPU: {}\".format(torch.cuda.get_device_name(0)))\n",
        "  device = torch.device(\"cuda\")\n",
        "  bert_lstm_model.cuda()\n",
        "else:\n",
        "  print(\"No GPUs available, using CPU\")\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOQhN8vlkEMb"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / labels_flat.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv4QTImb-9TH"
      },
      "outputs": [],
      "source": [
        "def get_max_checkpt(checkpt_dir):\n",
        "  max_checkpt = 0\n",
        "  for filename in os.listdir(checkpt_dir):\n",
        "    if re.match(r\"checkpt-([0-9]+).pt\", filename):\n",
        "      checkpt_num = int(filename.split('.')[-2].split('-')[-1])\n",
        "      if checkpt_num > max_checkpt:\n",
        "        max_checkpt = checkpt_num\n",
        "  return max_checkpt\n",
        "\n",
        "def load_latest_checkpt(checkpt_dir=CHECKPT_DIR):\n",
        "  if force_restart_training:\n",
        "    return\n",
        "  mx_checkpt = get_max_checkpt(checkpt_dir)\n",
        "  if mx_checkpt > 0:\n",
        "    checkpt_file = os.path.join(checkpt_dir, \"checkpt-{}.pt\".format(mx_checkpt))\n",
        "    bert_lstm_model.load_state_dict(torch.load(checkpt_file))\n",
        "  return mx_checkpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F_hoOdTipgk"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 50\n",
        "NUM_STEPS = len(train_dataloader) * NUM_TARGET_EPOCHS\n",
        "optimizer = AdamW(bert_lstm_model.parameters(), lr=2e-5, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=NUM_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqzwSy7psqax"
      },
      "outputs": [],
      "source": [
        "def train_bert_lstm():\n",
        "  loss_values = []\n",
        "  start_epoch = load_latest_checkpt() # 0-indexed\n",
        "  scheduler.last_epoch = start_epoch - 1\n",
        "  save = True\n",
        "  bert_lstm_model.train()\n",
        "  for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "    print(\"Using BERT-LSTM model\")\n",
        "    print(\"======== Epoch {} / {} ========\".format(epoch+1, NUM_EPOCHS))\n",
        "    print(\"Training phase\")\n",
        "    epoch_start = time.time()\n",
        "    epoch_loss = 0\n",
        "    bert_lstm_model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      if step % 40 == 0 and step != 0:\n",
        "        elapsed = format_time(time.time() - epoch_start)\n",
        "        print(\"Batch {} of {}. Elapsed {}\".format(step, len(train_dataloader), elapsed))\n",
        "      batch_enc_def = batch[0].to(device)\n",
        "      batch_attn_mask = batch[1].to(device)\n",
        "      batch_targets = batch[2].to(device) # These are the glove vectors\n",
        "      bert_lstm_model.zero_grad()\n",
        "      outputs = bert_lstm_model(input_ids=batch_enc_def, attention_mask=batch_attn_mask)\n",
        "      # This function takes logits and labels\n",
        "      MSE = nn.MSELoss(reduction='none')\n",
        "      loss = MSE(outputs, batch_targets)\n",
        "      loss = torch.mean(torch.sum(loss, axis=1))\n",
        "      epoch_loss += loss\n",
        "      loss.backward()\n",
        "      clip_grad_norm_(bert_lstm_model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "    avg_train_loss = epoch_loss / len(train_dataloader)\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"Average training loss for epoch {} : {}\".format(epoch+1, avg_train_loss))\n",
        "    print(\"Epoch took {}\".format(format_time(time.time()-epoch_start)))\n",
        "\n",
        "    print(\"\\nValidation phase\")\n",
        "    val_start = time.time()\n",
        "    bert_lstm_model.eval()\n",
        "    val_loss, val_accuracy = 0, 0\n",
        "    batch_eval_steps, batch_eval_examples = 0, 0\n",
        "    for batch in validation_dataloader:\n",
        "      batch = tuple(tup.to(device) for tup in batch)\n",
        "      batch_enc_def, batch_attn_mask, batch_targets = batch\n",
        "      with torch.no_grad():\n",
        "        outputs = bert_lstm_model(input_ids=batch_enc_def, attention_mask=batch_attn_mask)\n",
        "      MSE = nn.MSELoss(reduction='none')\n",
        "      loss = MSE(outputs, batch_targets)\n",
        "      loss = torch.mean(torch.sum(loss, axis=1))\n",
        "      val_loss += loss\n",
        "    avg_val_loss = val_loss / len(validation_dataloader)\n",
        "    print(\"Validation loss: {}\".format(avg_val_loss))\n",
        "    print(\"Validation took {}\".format(format_time(time.time()-val_start)))\n",
        "    if save:\n",
        "      checkpt_path = os.path.join(CHECKPT_DIR, \"checkpt-{}.pt\".format(epoch+1))\n",
        "      torch.save(bert_lstm_model.state_dict(), checkpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbnDsBzY_T8G"
      },
      "outputs": [],
      "source": [
        "train_bert_lstm()\n",
        "bert_lstm_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkGTbBj1xi3e"
      },
      "outputs": [],
      "source": [
        "def has_blocked_chars(word):\n",
        "  \"\"\"\n",
        "  Prune away words with spurious characters such as @\n",
        "  \"\"\"\n",
        "  return (word in sample_bad_words) or any(not char.isalpha() for char in word)\n",
        "\n",
        "def get_k_closest_words(vec, k=5, skip_implausible=True):\n",
        "  \"\"\"\n",
        "  Returns top k closest words when comparing - for now only k=1 is supported.\n",
        "  \"\"\"\n",
        "  vec = vec.detach().cpu().numpy().flatten()\n",
        "  closest = [None] * k\n",
        "  distances = [math.inf] * k\n",
        "  for word, wvec in glove_vectors.items():\n",
        "    if skip_implausible and has_blocked_chars(word):\n",
        "      continue\n",
        "    distance = np.linalg.norm(wvec-vec)\n",
        "    ind = 0\n",
        "    while ind < k and distances[ind] < distance:\n",
        "      ind += 1\n",
        "    if ind < k:\n",
        "      closest = closest[:ind] + [word] + closest[ind:-1]\n",
        "      distances = distances[:ind] + [distance] + distances[ind:-1]\n",
        "  return closest\n",
        "\n",
        "def get_closest_word(vec, skip_implausible=True):\n",
        "  \"\"\"\n",
        "  Gets the closest word among the glove words to the given vector\n",
        "  \"\"\"\n",
        "  vec = vec.detach().cpu().numpy().flatten()\n",
        "  closest = None\n",
        "  dmin = math.inf\n",
        "  for word, wvec in glove_vectors.items():\n",
        "    if skip_implausible and has_blocked_chars(word):\n",
        "      continue\n",
        "    distance = np.linalg.norm(wvec-vec)\n",
        "    if distance < dmin:\n",
        "      closest = word\n",
        "      dmin = distance\n",
        "  return closest\n",
        "\n",
        "def is_in_top_1_10_100(word, vec):\n",
        "  \"\"\"\n",
        "  Returns three booleans depicting whether the word is among the top 1, 10, and 100\n",
        "  closest ones respectively in terms of word vector distance to vec.\n",
        "  \"\"\"\n",
        "  words_100 = get_k_closest_words(vec=vec, k=100)\n",
        "  if word not in words_100:\n",
        "    return (0,0,0)\n",
        "  else:\n",
        "    idx = words_100.index(word)\n",
        "    if idx == 0:\n",
        "      return (1,1,1)\n",
        "    elif idx < 10:\n",
        "      return (0,1,1)\n",
        "    else:\n",
        "      return (0,0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psaZMs0gwHH4"
      },
      "outputs": [],
      "source": [
        "test_dataset = TensorDataset(*split_dataset['test'])\n",
        "test_sampler = SequentialSampler(test_dataset)                                  # Use a sequential sampler for testing since we may have to resume it after pausing\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_baseline(inputs):\n",
        "  gvec = np.zeros(100)\n",
        "  n = 0\n",
        "  for word in inputs.split():\n",
        "    if word in glove_vectors:\n",
        "      gvec += glove_vectors[word]\n",
        "      n += 1\n",
        "  if n > 0:\n",
        "    gvec /= n\n",
        "  return gvec\n",
        "\n",
        "def eval_baseline():\n",
        "  total = 0\n",
        "  n1 = 0\n",
        "  n10 = 0\n",
        "  n100 = 0\n",
        "  for sample in test_dataloader:\n",
        "    test_defs = bert_tokenizer.batch_decode(sequences=sample[0], skip_special_tokens=True)\n",
        "    targets = sample[2]\n",
        "    for i in range(targets.shape[0]):\n",
        "      word = torch.from_numpy(get_baseline(test_defs[i])).to(device)\n",
        "      top1, top10, top100 = is_in_top_1_10_100(targets[i], word)\n",
        "      n1 += top1\n",
        "      n10 += top10\n",
        "      n100 += top100\n",
        "      total += 1\n",
        "      print(total, \"done\")\n",
        "  print(total, n1, n10, n100)"
      ],
      "metadata": {
        "id": "7aaTn6zvM7q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w1Qr6ewXfZu"
      },
      "outputs": [],
      "source": [
        "def print_examples():\n",
        "  batch_0 = next(iter(test_dataloader))\n",
        "  batch_0_enc_def = batch_0[0].to(device)\n",
        "  batch_0_attn_mask = batch_0[1].to(device)\n",
        "  batch_0_targets = batch_0[2].to(device)\n",
        "\n",
        "  outputs = bert_lstm_model(input_ids=batch_0_enc_def, attention_mask=batch_0_attn_mask)\n",
        "  tests_decoded = []\n",
        "  targets_decoded = []\n",
        "  with torch.no_grad():\n",
        "    for i in range(outputs.shape[0]):\n",
        "      tests_decoded.append(get_closest_word(outputs[i].cpu()))\n",
        "      targets_decoded.append(get_closest_word(batch_0_targets[i].cpu()))\n",
        "      test_defs = bert_tokenizer.batch_decode(sequences=batch_0_enc_def, skip_special_tokens=True)\n",
        "  print(\"Some examples:\")\n",
        "  for i in range(len(targets_decoded)):\n",
        "    print(\"Definition: \", test_defs[i])\n",
        "    print(\"Our model's output:\", tests_decoded[i])\n",
        "    print(\"Real word:\", targets_decoded[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTyJJDkvMAJ_"
      },
      "outputs": [],
      "source": [
        "def get_testing_accuracies(dataloader, start=0, end=-1):\n",
        "  total = 0\n",
        "  n1 = 0\n",
        "  n10 = 0\n",
        "  n100 = 0\n",
        "  for batch in dataloader:\n",
        "    if start >= batch[2].shape[0]:\n",
        "      start -= BATCH_SIZE\n",
        "      continue\n",
        "    batch_enc_def = batch[0].to(device)\n",
        "    batch_attn_mask = batch[1].to(device)\n",
        "    batch_targets = batch[2].to(device)\n",
        "    outputs = bert_lstm_model(input_ids=batch_enc_def, attention_mask=batch_attn_mask)\n",
        "    for i in range(start, outputs.shape[0]):\n",
        "      actual = get_closest_word(batch_targets[i].cpu())\n",
        "      top1, top10, top100 = is_in_top_1_10_100(actual, outputs[i])\n",
        "      total += 1\n",
        "      n1 += top1\n",
        "      n10 += top10\n",
        "      n100 += top100\n",
        "      start = 0\n",
        "      if i % 100 == 99:\n",
        "        print(\"{} done.\".format(i+1))\n",
        "      if total == end:\n",
        "        break\n",
        "    if total == end:\n",
        "      break\n",
        "  p1 = 100.0 * n1 / total\n",
        "  p10 = 100.0 * n10 / total\n",
        "  p100 = 100.0 * n100 / total\n",
        "  print(\"Top 1 accuracy  : 100% * {} / {} = {}%\".format(n1, total, p1))\n",
        "  print(\"Top 10 accuracy : 100% * {} / {} = {}%\".format(n10, total, p10))\n",
        "  print(\"Top 100 accuracy: 100% * {} / {} = {}%\".format(n100, total, p100))\n",
        "  return n1, n10, n100, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvS_c5JSYVEz"
      },
      "outputs": [],
      "source": [
        "def get_word_from_single_def(definition, tokenizer, use_bert_lstm=True):\n",
        "  single_word_dset = [[\"\", definition]]\n",
        "  encoded = encode_data(single_word_dset, tokenizer)\n",
        "  defn = encoded[0].to(device)\n",
        "  mask = encoded[1].to(device)\n",
        "  outputs = bert_lstm_model(input_ids=defn, attention_mask=mask)\n",
        "  return [get_closest_word(outputs[0])]\n",
        "\n",
        "def get_k_closest_words_from_single_def(definition, tokenizer, use_bert_lstm=True):\n",
        "  single_word_dset = [[\"\", definition]]\n",
        "  encoded = encode_data(single_word_dset, tokenizer)\n",
        "  defn = encoded[0].to(device)\n",
        "  mask = encoded[1].to(device)\n",
        "  outputs = bert_lstm_model(input_ids=defn, attention_mask=mask)\n",
        "  return get_k_closest_words(outputs[0], k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APhLSyABZvmK",
        "outputId": "d36f5f48-38e8-4d5b-c5b5-5d887117ec99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Dataset Accuracy:\n",
            "Top 1: 48.70627199337611%\n",
            "Top 10: 58.9525978058373%\n",
            "Top 100: 65.61788449596357%\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  with open('/content/gdrive/MyDrive/accuracy.txt') as f:\n",
        "    x = f.readlines()[0].split()\n",
        "    x = [int(i) for i in x]\n",
        "  if (x[0] == len(test_dataset)):\n",
        "    break\n",
        "  n1, n10, n100, total = get_testing_accuracies(test_dataloader, x[0], 64)\n",
        "  x[0] += total\n",
        "  x[1] += n1\n",
        "  x[2] += n10\n",
        "  x[3] += n100\n",
        "  with open('/content/gdrive/MyDrive/accuracy.txt', 'w+') as f:\n",
        "    f.write(\"{} {} {} {}\\n\".format(*x))\n",
        "  print(*x, sep=' ')\n",
        "print(\"Test Dataset Accuracy:\")\n",
        "print(\"Top 1: {}%\".format(100.0*x[1]/x[0]))\n",
        "print(\"Top 10: {}%\".format(100.0*x[2]/x[0]))\n",
        "print(\"Top 100: {}%\".format(100.0*x[3]/x[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujftz0GBJKcm",
        "outputId": "d34928b8-d333-41c8-a08e-2032da8f0963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some examples:\n",
            "Definition:  in a mutual or shared manner\n",
            "Our model's output: mutually\n",
            "Real word: mutually\n",
            "Definition:  morally reprehensible\n",
            "Our model's output: pathetic\n",
            "Real word: slimy\n",
            "Definition:  a list of divisions ( chapters or articles ) and the pages on which they start\n",
            "Our model's output: contents\n",
            "Real word: contents\n",
            "Definition:  not working properly\n",
            "Our model's output: defective\n",
            "Real word: bad\n",
            "Definition:  not influenced or affected\n",
            "Our model's output: unswayed\n",
            "Real word: uninfluenced\n",
            "Definition:  cause to sense ; make sensitive\n",
            "Our model's output: sensitize\n",
            "Real word: sensitize\n",
            "Definition:  small fishes found in great schools along coasts of europe ; smaller and rounder than herring\n",
            "Our model's output: pilchard\n",
            "Real word: pilchard\n",
            "Definition:  keep from happening or arising ; make impossible\n",
            "Our model's output: preclude\n",
            "Real word: prevent\n",
            "Definition:  cut or tear along an irregular line so that the parts can later be matched for authentication\n",
            "Our model's output: indent\n",
            "Real word: indented\n",
            "Definition:  anything ( straws or pebbles etc. ) taken or chosen at random\n",
            "Our model's output: draw\n",
            "Real word: draw\n",
            "Definition:  used of skin roughened as a result of cold or exposure\n",
            "Our model's output: chapped\n",
            "Real word: chapped\n",
            "Definition:  a tract of land where logs are accumulated\n",
            "Our model's output: yard\n",
            "Real word: yard\n",
            "Definition:  measuring instrument for measuring the luminous intensity of a source by comparing it ( visually or photoelectrically ) with a standard source\n",
            "Our model's output: photometer\n",
            "Real word: photometer\n",
            "Definition:  put at risk\n",
            "Our model's output: dellcptr\n",
            "Real word: venture\n",
            "Definition:  a human female employed to do housework\n",
            "Our model's output: woman\n",
            "Real word: charwoman\n",
            "Definition:  a deduction allowed to a taxpayer because of his or her status ( having certain dependents or being blind or being over 65 etc. )\n",
            "Our model's output: exemption\n",
            "Real word: exemption\n",
            "Definition:  become affected with smut\n",
            "Our model's output: smut\n",
            "Real word: smut\n",
            "Definition:  a warrant to take someone into custody\n",
            "Our model's output: pickup\n",
            "Real word: pickup\n",
            "Definition:  an assertion that something is true or factual\n",
            "Our model's output: claim\n",
            "Real word: claim\n",
            "Definition:  ( used of soaps or cleaning agents ) having a substance ( an abrasive or filler ) added to increase effectiveness\n",
            "Our model's output: built\n",
            "Real word: built\n",
            "Definition:  an electrical device that sends or receives radio or television signals\n",
            "Our model's output: antennas\n",
            "Real word: antenna\n",
            "Definition:  mold consisting of a box with sand shaped to mold metal\n",
            "Our model's output: sandbox\n",
            "Real word: sandbox\n",
            "Definition:  a quick blow delivered with a whip or whiplike object\n",
            "Our model's output: lash\n",
            "Real word: whip\n",
            "Definition:  a person ( or institution ) to whom legal title to property is entrusted to use for another's benefit\n",
            "Our model's output: trustee\n",
            "Real word: trustee\n",
            "Definition:  ( of verse ) having a metric system based on relative duration of syllables\n",
            "Our model's output: quantitative\n",
            "Real word: quantitative\n",
            "Definition:  calling up a spirit or devil\n",
            "Our model's output: ooooooooooooooooooooooooooooooooooooooo\n",
            "Real word: conjuration\n",
            "Definition:  ( astronomy ) a cluster of stars ( or a small constellation )\n",
            "Our model's output: asterism\n",
            "Real word: asterism\n",
            "Definition:  a kind of sealing material that is used to form a hard coating on a porous surface ( as a coat of paint or varnish used to size a surface )\n",
            "Our model's output: sealant\n",
            "Real word: sealant\n",
            "Definition:  ( of the more skilled contestants ) selectively arranged in the draw for position in a tournament so that they meet each other in later rounds\n",
            "Our model's output: seeded\n",
            "Real word: seeded\n",
            "Definition:  a solemn pledge ( to oneself or to another or to a deity ) to do something or to behave in a certain manner\n",
            "Our model's output: vow\n",
            "Real word: vowed\n",
            "Definition:  an instance of questioning\n",
            "Our model's output: questioning\n",
            "Real word: enquiry\n",
            "Definition:  small tubular solitary freshwater hydrozoan polyp\n",
            "Our model's output: wobbegong\n",
            "Real word: hydra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RisClyMyWVHJ",
        "outputId": "2d51c287-b789-4001-8d1a-31066bb68f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bat\n"
          ]
        }
      ],
      "source": [
        "definition = \"sport which uses bat and ball.\"\n",
        "with torch.no_grad():\n",
        "  print(get_word_from_single_def(definition, bert_tokenizer)[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "definition = \"\"\n",
        "with torch.no_grad():\n",
        "  print(get_k_closest_words_from_single_def(definition, bert_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKUHv2LYN-yB",
        "outputId": "92b2fa2e-f065-45e1-ea7a-3755edc145c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['invocation', 'benediction', 'paean', 'denunciation', 'ooooooooooooooooooooooooooooooooooooooo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GRMITdQdXy39"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ReverseDictionary.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d582974fe76462f92e2d957aa31d57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fdbf3001762477c9261e1b7648c10ef",
              "IPY_MODEL_4b60c84d3e88466d8593a169b7e751f2",
              "IPY_MODEL_34bf1db35ad447ea98ad39b00bce5d14"
            ],
            "layout": "IPY_MODEL_48b20c56669e4e378eed28883b8a8807"
          }
        },
        "1fdbf3001762477c9261e1b7648c10ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9fba806780492795ee3c72f1eab3f4",
            "placeholder": "​",
            "style": "IPY_MODEL_05a9c56edf1f41e2a627365a26b51569",
            "value": "Downloading: 100%"
          }
        },
        "4b60c84d3e88466d8593a169b7e751f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d52c2ff788db41828f3d92abbd153cca",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_347b136abd1f48dd931b8654f92ee8e5",
            "value": 28
          }
        },
        "34bf1db35ad447ea98ad39b00bce5d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1996ca31014e430eac7a5ba4eaed6ff3",
            "placeholder": "​",
            "style": "IPY_MODEL_085e3edfb2c94706b01d5bf07a40602b",
            "value": " 28.0/28.0 [00:00&lt;00:00, 608B/s]"
          }
        },
        "48b20c56669e4e378eed28883b8a8807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc9fba806780492795ee3c72f1eab3f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a9c56edf1f41e2a627365a26b51569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d52c2ff788db41828f3d92abbd153cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347b136abd1f48dd931b8654f92ee8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1996ca31014e430eac7a5ba4eaed6ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "085e3edfb2c94706b01d5bf07a40602b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a06643ada44c417ab144dfd1e3147b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55b10b8b85ae493b88c41226189aedc0",
              "IPY_MODEL_7f243f1931314cdf82f1abf1f23a9b40",
              "IPY_MODEL_cf4835f94f41464a858916f1b80bb7c2"
            ],
            "layout": "IPY_MODEL_3960e22357fb4a918aeb9454e9d74318"
          }
        },
        "55b10b8b85ae493b88c41226189aedc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380142a4448e44bc94c4b8bcdcb1055f",
            "placeholder": "​",
            "style": "IPY_MODEL_c467eab7e57149ad95dc8d3376903293",
            "value": "Downloading: 100%"
          }
        },
        "7f243f1931314cdf82f1abf1f23a9b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f18492e87ee74868b8b482bf91fd8043",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87c6878092f64393ada9b65599827146",
            "value": 570
          }
        },
        "cf4835f94f41464a858916f1b80bb7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a2a6234a384683a9f54a3d356cc9b5",
            "placeholder": "​",
            "style": "IPY_MODEL_ccf3c03711af4cfd9dd516ab081644b3",
            "value": " 570/570 [00:00&lt;00:00, 21.1kB/s]"
          }
        },
        "3960e22357fb4a918aeb9454e9d74318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "380142a4448e44bc94c4b8bcdcb1055f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c467eab7e57149ad95dc8d3376903293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f18492e87ee74868b8b482bf91fd8043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c6878092f64393ada9b65599827146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23a2a6234a384683a9f54a3d356cc9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf3c03711af4cfd9dd516ab081644b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f9702994f2a46b9aecd4d7804d48a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_349e26524c5b49afad8fcf350657c755",
              "IPY_MODEL_16998aeb988c47208383f64b16ae4d5b",
              "IPY_MODEL_3e4b2a2f879b47a38d615323c1f6e00b"
            ],
            "layout": "IPY_MODEL_adaade3fce094873bc2b45c19c0e9574"
          }
        },
        "349e26524c5b49afad8fcf350657c755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7191804896d4295bc28a27d5d183538",
            "placeholder": "​",
            "style": "IPY_MODEL_351345989f79465ca4ab48fc4d94282a",
            "value": "Downloading: 100%"
          }
        },
        "16998aeb988c47208383f64b16ae4d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_341e26b547eb4294bf34323f91815ccb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b1b3fffea8e436aa61542fd987fe5e2",
            "value": 231508
          }
        },
        "3e4b2a2f879b47a38d615323c1f6e00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cafec97633547f698b3999c4bd17796",
            "placeholder": "​",
            "style": "IPY_MODEL_57fdc89b532a44b48354364a87766bde",
            "value": " 226k/226k [00:00&lt;00:00, 736kB/s]"
          }
        },
        "adaade3fce094873bc2b45c19c0e9574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7191804896d4295bc28a27d5d183538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "351345989f79465ca4ab48fc4d94282a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "341e26b547eb4294bf34323f91815ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b1b3fffea8e436aa61542fd987fe5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cafec97633547f698b3999c4bd17796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57fdc89b532a44b48354364a87766bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf37d8334526400a88ed2f64fbd1b5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f38d8e899ae84fec9b79c86885a95d69",
              "IPY_MODEL_33f42f6992ec45c6942009a7b82801bd",
              "IPY_MODEL_1e07c1e24d9c4a9eb1ceb69eef368acf"
            ],
            "layout": "IPY_MODEL_2ce529c0f097411dab55b1f581dd5cbe"
          }
        },
        "f38d8e899ae84fec9b79c86885a95d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71bba25cb87f43a5934597d43d0610ec",
            "placeholder": "​",
            "style": "IPY_MODEL_5c114c121020453a80b3f674549ac071",
            "value": "Downloading: 100%"
          }
        },
        "33f42f6992ec45c6942009a7b82801bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a104ebe00ff427bbe8f84e6f46a453e",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a01aa2977b0e4cc0bf5ef1e5fbb13a0e",
            "value": 466062
          }
        },
        "1e07c1e24d9c4a9eb1ceb69eef368acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_466e7d9b5b6747139e100d084ca15501",
            "placeholder": "​",
            "style": "IPY_MODEL_32bf7a57fed64da49ce5c8bb01552c05",
            "value": " 455k/455k [00:00&lt;00:00, 1.05MB/s]"
          }
        },
        "2ce529c0f097411dab55b1f581dd5cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71bba25cb87f43a5934597d43d0610ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c114c121020453a80b3f674549ac071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a104ebe00ff427bbe8f84e6f46a453e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01aa2977b0e4cc0bf5ef1e5fbb13a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "466e7d9b5b6747139e100d084ca15501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32bf7a57fed64da49ce5c8bb01552c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f8ce995b6ca4f94b10e57b19d0cf2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d47690128a134680a60b5813d0c0ff83",
              "IPY_MODEL_eb2ba6dd6baa43c69e34935885bbce6a",
              "IPY_MODEL_c1c1155b1a6f4220b3d857ed71b507a4"
            ],
            "layout": "IPY_MODEL_6787fe18dd0f464ca7962b6430a26be3"
          }
        },
        "d47690128a134680a60b5813d0c0ff83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40d4ac620cc64d10af68252512ac375c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a140f7c06734d008b6cf007ad9adad6",
            "value": "Downloading: 100%"
          }
        },
        "eb2ba6dd6baa43c69e34935885bbce6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06f5aea3055148f18fa6bcbce9f5a5b0",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f7d5d829bd14ec1900d46b2bd6d4b1a",
            "value": 440473133
          }
        },
        "c1c1155b1a6f4220b3d857ed71b507a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5710e209df1435488c286ab3a3e0cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_17337d42ecfe45889a3be40b95aa6b83",
            "value": " 420M/420M [00:07&lt;00:00, 58.7MB/s]"
          }
        },
        "6787fe18dd0f464ca7962b6430a26be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d4ac620cc64d10af68252512ac375c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a140f7c06734d008b6cf007ad9adad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06f5aea3055148f18fa6bcbce9f5a5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f7d5d829bd14ec1900d46b2bd6d4b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5710e209df1435488c286ab3a3e0cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17337d42ecfe45889a3be40b95aa6b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}